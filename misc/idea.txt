ApertureIO Idea

GPU Abstraction Layer. For General Purpose GPU Processing to deliver 2D/3D Content.
Feature Set
    GPU Abstractions
        Instance
        Device
            Device Selections
            API Selection - I think for now the focus just on using Vulkan
        Buffer
            IndexBuffers*
            VertexBuffers*
            
            Device Memory

            Data Layout / Format
                Vertex Layout
                Pos:Vec3 Dir:3Vec3 Nor:Vec3 Color:Vec3
                Image Layout
                R:Float G:Float B:Float

        FrameBuffers
            Render Targets - Research More..
            Render Passes - Research More..
            Depth Testing
            General New Passes like Normals, Wireframe

        Pipeline
            Descriptors
            Descriptor Sets Layouts
            Descriptor Sets
            Pipeline Layout
            
        Textures
            Images
            ImageViews
        SwapChains
            Surfaces?
        Shaders
            Fragment Shaders
            Vertex Shaders
            Compute Shaders
        Commands
            Render Commands
            Compute Commands
            Transfer Commands?
        Queues
            Graphics Queue
            Compute Queue
            Transfer Queue? - Research More..
        Synchronize
            Fences
            Semaphore
        
        Usage:
            Interface for for submit commands to the GPU and
            allocating GPU related Objects like Buffers.

    Our Functions
    GPUContext ApertureIO::Context
        whole data like our rendering context. Like our vulkan instance.
        Will handle stuff like extension, API version and even what API
        we are using, Current Frame, Frames In Flight Settings

    GPUDevice ApertureIO::Device
        This will be related to a logical device that we will be working with.
        The user can have multiple devices in one applications. But they can't 
        share resources or workload. *note might restricts this to one GPU but this
        will be the active GPU for using.
    
    GPUCommand ApertureIO::Command
        This will be Commands that we can submitted to the GPUDevice like
        BeginFrame, EndFrame, Draw, DrawInstanced, Dispatch, Clear, Copy.    

    GPUBuffer ApertureIO::Buffer
        A buffer that storage data that the GPUDevice can use.
        This will mostly likely only be stuff like vertex buffers,
        index buffers and storage buffers. 
        
        Something to think about here is using bindless
        descriptor set instead of having to manually deal
        with creating an DescriptorSetLayout. This means that
        we can just need to set how many slots that pipeline 
        will need. But we will need to be more careful as 
        we wont have any protection for accessing memory that
        we shouldn't be.

        *Uniform buffers will be handled within the shader.

        READ MORE HERE:
        https://dev.to/gasim/implementing-bindless-design-in-vulkan-34no

    GPUFrameBuffer ApertureIO::FrameBuffer
        The framebuffer will be used as our image that
        we will be writing to.
        This can be set with active window for direct window rendering.
        This could also just be set as a image to write to disk for 
        graphics and compute rendering. (This means it wouldn't need 
        a swapchain for it).
        The user should be able to set n layers and channels like with
        EXRs files. 

        // this doesn't need to be an object to use!!! 
        GPUSwapChain ApertureIO::SwapChain
            This object interacts with the windows and presents
            the rendered framebuffer to the screen.

    // Think about if you really want this or not
    GPUTexture ApertureIO::Texture
        This would be an READ only format for textures.
        To be used within an shader.
        Think of it as the Read node inside of Nuke.
        For Reading textures.
    
    Shader AND ShaderLibrary ApertureIO::Shader
        Objects for storing, compiling, binding shaders.
        Users can using SetUniform4 and a Name to create
        UniformBuffers with that shader.
        
        *note deffo need to look into how we can use shared
        files for defining the structs for our shaders and applications.



    RenderGraph or ProcessGraph
    ApertureIO::ProcessGraph
        Research:
        https://poniesandlight.co.uk/reflect/island_rendergraph_1/
        https://logins.github.io/graphics/2021/05/31/RenderGraphs.html
        https://apoorvaj.io/render-graphs-1/

        ProcessGraph for organizing Render Passes and Compute Passes.
        Usage:
            Users should be able to implement different types of render passes 
            and compute passes and define the path of execution by they placement
            within the graph.

            Each point of the graph will have arguments that controls the results of that
            pass. They will also take a output render target or storage buffer and maybe an 
            input target/buffer for passes like blurs.

            On every frame, we will travel thought the graph starting from the top and 
            working our way down to the bottom. 

            States - Research More..
            We will need to have states on these points on the graph, so that we
            know what the status is of the points. Like if it's ready for render / compute
            or is it waiting or somethng like that.

            Memory Management - because the graph will already know every resources it needs before
            execution and when it needs it. It can manage the resources by reusing the same resources
            when it knows a pass doesn't need it anymore.

            Hash - We will be storing an hash of each pass based off it's arguments
            generated hash. This will mean we can check to see if we need to rebuild
            the graph or if we can just reuse the same graphs.  

            Debug Features:
                Export Image of the Graph

////////////////////////////////////////////////////////////////////////
////////////////////// Pointless Stuff Under here //////////////////////
////////////////////////////////////////////////////////////////////////

Library Name
DashGFX
DashGPU
DashRenderer
GPUDash
Iris
apertureIO::Device
Aio::Device

////////////////////////////////////////////////////////////////////////
////////////////////// Things I need to think about ////////////////////
////////////////////////////////////////////////////////////////////////

Window
I don't really want to have to manage the window object and i really
dont want to abstract it too. So think about what information I need to know
related to the window. The main thing is the surface object.

Framebuffers / Window / SwapChains
To render to a window using vulkan, we need to setup 
a swapchain connected to the surface from the window.
This will also have to be an framebuffer as it will be the
used as the render target for our rendering.
Context knows about the current window we are trying to renderer to.
From that we can always get the the surface...

Context -> (Active)Window Surface
Output Target Framebuffer -> Context
If Output Target Framebuffer:
    Stores Swapchain Info

So I don't need to create the surface but i expect the window api to
create the window for us.

Hot-Loading.

For handling shaders, instead of using the glsl.exe to compile the
shaders. We will do it at runtime and also set up a watcher on the 
shader source file to track for any changes on the shader. If the
source has been modifed then we will start rebuilding a new shader
with. Then swap it with the out of data shader once it's ready to use.

Watching Source files should happen on the base classes not vulkan classes!


